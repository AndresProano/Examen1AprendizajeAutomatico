{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b1c3465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_16424\\1615212929.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "x = data\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7538bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\n",
    "    \"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\",\n",
    "    \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"\n",
    "]\n",
    "df = pd.DataFrame(x, columns=columnas)\n",
    "df['MEDV'] = y  # Agregar la variable objetivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0de4960",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'get_data_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columnas:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\OneDrive\\Escritorio\\GitHub\\ExamenAprendizajeAutomatico\\Examen1AprendizajeAutomatico\\.venv\\Lib\\site-packages\\matplotlib\\__init__.py:1001\u001b[39m\n\u001b[32m    995\u001b[39m     _log.debug(\u001b[33m'\u001b[39m\u001b[33mloaded rc file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m, fname)\n\u001b[32m    997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[32m   1000\u001b[39m rcParamsDefault = _rc_params_in_file(\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     \u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_data_path\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmatplotlibrc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m   1002\u001b[39m     \u001b[38;5;66;03m# Strip leading comment.\u001b[39;00m\n\u001b[32m   1003\u001b[39m     transform=\u001b[38;5;28;01mlambda\u001b[39;00m line: line[\u001b[32m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m line.startswith(\u001b[33m\"\u001b[39m\u001b[33m#\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m line,\n\u001b[32m   1004\u001b[39m     fail_on_error=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1005\u001b[39m rcParamsDefault._update_raw(rcsetup._hardcoded_defaults)\n\u001b[32m   1006\u001b[39m rcParamsDefault._ensure_has_backend()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andre\\OneDrive\\Escritorio\\GitHub\\ExamenAprendizajeAutomatico\\Examen1AprendizajeAutomatico\\.venv\\Lib\\site-packages\\matplotlib\\cbook.py:603\u001b[39m, in \u001b[36m_get_data_path\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_data_path\u001b[39m(*args):\n\u001b[32m    598\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m    Return the `pathlib.Path` to a resource file provided by Matplotlib.\u001b[39;00m\n\u001b[32m    600\u001b[39m \n\u001b[32m    601\u001b[39m \u001b[33;03m    ``*args`` specify a path relative to the base data path.\u001b[39;00m\n\u001b[32m    602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Path(\u001b[43mmatplotlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data_path\u001b[49m(), *args)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'matplotlib' has no attribute 'get_data_path'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for col in columnas:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.scatterplot(x=df[col], y=df[\"MEDV\"])\n",
    "    plt.title(f\"Relación entre {col} y MEDV\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"MEDV\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0de7bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDV       1.000000\n",
      "RM         0.695360\n",
      "ZN         0.360445\n",
      "B          0.333461\n",
      "DIS        0.249929\n",
      "CHAS       0.175260\n",
      "AGE       -0.376955\n",
      "RAD       -0.381626\n",
      "CRIM      -0.388305\n",
      "NOX       -0.427321\n",
      "TAX       -0.468536\n",
      "INDUS     -0.483725\n",
      "PTRATIO   -0.507787\n",
      "LSTAT     -0.737663\n",
      "Name: MEDV, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlaciones = df.corr()[\"MEDV\"].sort_values(ascending=False)\n",
    "print(correlaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c15ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a) Modelo lineal gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1dd6cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Model – MAE: 3.39 ± 0.22\n",
      "Gaussian Model – RMSE: 4.91 ± 0.45\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "x = df.drop(columns=[\"MEDV\"])\n",
    "y = df[\"MEDV\"].values\n",
    "\n",
    "X_sm = sm.add_constant(x, has_constant='add')\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=50, test_size=0.3, random_state=42)\n",
    "\n",
    "mae_scores_mlg, rmse_scores_mlg = [], []\n",
    "\n",
    "for train_index, test_index in splitter.split(X_sm.values):\n",
    "    X_train, X_test = X_sm.iloc[train_index], X_sm.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model_gaussian = sm.GLM(y_train, X_train, family=sm.families.Gaussian())\n",
    "    fitted = model_gaussian.fit()\n",
    "\n",
    "    y_pred_gaussian = fitted.predict(X_test)\n",
    "\n",
    "    mae_scores_mlg.append(mean_absolute_error(y_test, y_pred_gaussian))\n",
    "    rmse_scores_mlg.append(mean_squared_error(y_test, y_pred_gaussian) ** 0.5)\n",
    "\n",
    "\n",
    "mae_median = np.median(mae_scores_mlg)\n",
    "mae_std = np.std(mae_scores_mlg, ddof=1)\n",
    "rmse_median = np.median(rmse_scores_mlg)\n",
    "rmse_std = np.std(rmse_scores_mlg, ddof=1)\n",
    "\n",
    "print(f\"Gaussian Model – MAE: {mae_median:.2f} ± {mae_std:.2f}\")\n",
    "print(f\"Gaussian Model – RMSE: {rmse_median:.2f} ± {rmse_std:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b) Modelo lineal con regularización Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cdb8573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net – MAE: 3.36 ± 0.22\n",
      "Elastic Net – RMSE: 4.90 ± 0.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"elastic__alpha\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"elastic__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9, 0.99],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"elastic\", ElasticNet(max_iter=5000, random_state=42))\n",
    "])\n",
    "\n",
    "inner_cv = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "splitter = ShuffleSplit(n_splits=50, test_size=0.3, random_state=42)\n",
    "\n",
    "mae_scores, rmse_scores = [], []\n",
    "\n",
    "for train_idx, test_idx in splitter.split(X_sm.values):\n",
    "    X_train, X_test = X_sm.iloc[train_idx], X_sm.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=inner_cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "    rmse_scores.append(mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "\n",
    "mae_median = np.median(mae_scores)\n",
    "mae_std = np.std(mae_scores, ddof=1)\n",
    "rmse_median = np.median(rmse_scores)\n",
    "rmse_std = np.std(rmse_scores, ddof=1)\n",
    "\n",
    "print(f\"Elastic Net – MAE: {mae_median:.2f} ± {mae_std:.2f}\")\n",
    "print(f\"Elastic Net – RMSE: {rmse_median:.2f} ± {rmse_std:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210798e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo lineal con componentes principales (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93bdcc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + LR – MAE: 3.39 ± 0.22\n",
      "PCA + LR – RMSE: 4.91 ± 0.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold, ShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [5, 7, 9, 11, None]\n",
    "}\n",
    "\n",
    "inner_cv = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "splitter = ShuffleSplit(n_splits=50, test_size=0.3, random_state=42)\n",
    "\n",
    "mae_scores, rmse_scores = [], []\n",
    "\n",
    "for train_idx, test_idx in splitter.split(X_sm.values):\n",
    "    X_train, X_test = X_sm.iloc[train_idx], X_sm.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=inner_cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "    rmse_scores.append(mean_squared_error(y_test, y_pred)**0.5)\n",
    "\n",
    "mae_median = np.median(mae_scores)\n",
    "mae_std = np.std(mae_scores, ddof=1)\n",
    "rmse_median = np.median(rmse_scores)\n",
    "rmse_std = np.std(rmse_scores, ddof=1)\n",
    "\n",
    "print(f\"PCA + LR – MAE: {mae_median:.2f} ± {mae_std:.2f}\")\n",
    "print(f\"PCA + LR – RMSE: {rmse_median:.2f} ± {rmse_std:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maquinas de Vector de Soporte para Regresión SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3bf2821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR – MAE:  2.35 ± 0.25\n",
      "SVR – RMSE: 3.88 ± 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, KFold, ShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "svr_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svr\", SVR())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"svr__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"svr__C\": [0.1, 1, 10],\n",
    "    \"svr__epsilon\": [0.01, 0.1, 1],\n",
    "    \"svr__gamma\": [\"scale\", \"auto\"]  # solo se usa cuando kernel='rbf'\n",
    "}\n",
    "\n",
    "inner_cv = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "splitter = ShuffleSplit(n_splits=50, test_size=0.3, random_state=42)\n",
    "\n",
    "mae_scores, rmse_scores = [], []\n",
    "\n",
    "for train_idx, test_idx in splitter.split(X_sm.values):\n",
    "    X_train, X_test = X_sm.iloc[train_idx], X_sm.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        svr_pipeline,\n",
    "        param_grid,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=inner_cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "    rmse_scores.append(mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "\n",
    "mae_median = np.median(mae_scores)\n",
    "mae_std = np.std(mae_scores, ddof=1)\n",
    "rmse_median = np.median(rmse_scores)\n",
    "rmse_std = np.std(rmse_scores, ddof=1)\n",
    "\n",
    "print(f\"SVR – MAE:  {mae_median:.2f} ± {mae_std:.2f}\")\n",
    "print(f\"SVR – RMSE: {rmse_median:.2f} ± {rmse_std:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árbol de decisión para regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45cbd0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree – MAE:  2.97 ± 0.42\n",
      "Decision Tree – RMSE: 4.53 ± 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, ShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "dtree = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5]\n",
    "}\n",
    "\n",
    "inner_cv = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "splitter = ShuffleSplit(n_splits=50, test_size=0.3, random_state=42)\n",
    "\n",
    "mae_scores, rmse_scores = [], []\n",
    "\n",
    "for train_idx, test_idx in splitter.split(X_sm.values):\n",
    "    X_train, X_test = X_sm.iloc[train_idx], X_sm.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        dtree,\n",
    "        param_grid,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=inner_cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "    rmse_scores.append(mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "\n",
    "mae_median = np.median(mae_scores)\n",
    "mae_std = np.std(mae_scores, ddof=1)\n",
    "rmse_median = np.median(rmse_scores)\n",
    "rmse_std = np.std(rmse_scores, ddof=1)\n",
    "\n",
    "print(f\"Decision Tree – MAE:  {mae_median:.2f} ± {mae_std:.2f}\")\n",
    "print(f\"Decision Tree – RMSE: {rmse_median:.2f} ± {rmse_std:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.dataset_load(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"fedesoriano/stroke-prediction-dataset\",\n",
    "  \"healthcare-dataset-stroke-data.csv\",\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0662963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enfoque inferencial\n",
    "#Vamos a usar GLMs bernoulli y Gaussiana, Regularizacion Lasso o Ridge o Elastic Net junto con PCA\n",
    "#Tambien se utilizara la division en train/test y validacion cruzada k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722033f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
